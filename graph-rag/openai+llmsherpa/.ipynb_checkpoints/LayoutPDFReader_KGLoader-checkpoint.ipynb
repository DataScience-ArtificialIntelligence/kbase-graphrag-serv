{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llmsherpa\n",
      "  Downloading llmsherpa-0.1.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: urllib3 in /Users/adityaraj/miniconda3/lib/python3.11/site-packages (from llmsherpa) (1.26.18)\n",
      "Downloading llmsherpa-0.1.4-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: llmsherpa\n",
      "Successfully installed llmsherpa-0.1.4\n"
     ]
    }
   ],
   "source": [
    "!pip install llmsherpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting neo4j\n",
      "  Downloading neo4j-5.28.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: pytz in /Users/adityaraj/miniconda3/lib/python3.11/site-packages (from neo4j) (2022.7.1)\n",
      "Downloading neo4j-5.28.1-py3-none-any.whl (312 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.3/312.3 kB\u001b[0m \u001b[31m476.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: neo4j\n",
      "Successfully installed neo4j-5.28.1\n"
     ]
    }
   ],
   "source": [
    "!pip install neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# This is the demo of:\n",
    "#   - using LayoutPDFReader to read PDF files\n",
    "#   - mapping PDF elements into a property graph\n",
    "#   - saving PDF elements into Neo4j\n",
    "#\n",
    "\n",
    "from llmsherpa.readers import LayoutPDFReader\n",
    "\n",
    "llmsherpa_api_url = \"http://localhost:5010/api/parseDocument?renderFormat=all\"\n",
    "\n",
    "file_location = '/Users/adityaraj/Downloads/Papers'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import uuid\n",
    "import hashlib\n",
    "\n",
    "# Please change the following variables to your own Neo4j instance\n",
    "NEO4J_URL = \"neo4j+s://e147ea1b.databases.neo4j.io\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"3LS5xO8LnFRiG5kbkZgxNykIz76e9Wh618IeXpXDYBM\"\n",
    "NEO4J_DATABASE = \"neo4j\"\n",
    "\n",
    "\n",
    "def initialiseNeo4j():\n",
    "    cypher_schema = [\n",
    "        \"CREATE CONSTRAINT sectionKey IF NOT EXISTS FOR (c:Section) REQUIRE (c.key) IS UNIQUE;\",\n",
    "        \"CREATE CONSTRAINT chunkKey IF NOT EXISTS FOR (c:Chunk) REQUIRE (c.key) IS UNIQUE;\",\n",
    "        \"CREATE CONSTRAINT documentKey IF NOT EXISTS FOR (c:Document) REQUIRE (c.url_hash) IS UNIQUE;\",\n",
    "        \"CREATE CONSTRAINT tableKey IF NOT EXISTS FOR (c:Table) REQUIRE (c.key) IS UNIQUE;\",\n",
    "        \"CALL db.index.vector.createNodeIndex('chunkVectorIndex', 'Embedding', 'value', 1536, 'COSINE');\"\n",
    "    ]\n",
    "\n",
    "    driver = GraphDatabase.driver(NEO4J_URL, database=NEO4J_DATABASE, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "\n",
    "    with driver.session() as session:\n",
    "        for cypher in cypher_schema:\n",
    "            session.run(cypher)\n",
    "    driver.close()\n",
    "    \n",
    "\n",
    "def ingestDocumentNeo4j(doc, doc_location):\n",
    "\n",
    "\n",
    "    cypher_pool = [\n",
    "        # 0 - Document\n",
    "        \"MERGE (d:Document {url_hash: $doc_url_hash_val}) ON CREATE SET d.url = $doc_url_val RETURN d;\",  \n",
    "        # 1 - Section\n",
    "        \"MERGE (p:Section {key: $doc_url_hash_val+'|'+$block_idx_val+'|'+$title_hash_val}) ON CREATE SET p.page_idx = $page_idx_val, p.title_hash = $title_hash_val, p.block_idx = $block_idx_val, p.title = $title_val, p.tag = $tag_val, p.level = $level_val RETURN p;\",\n",
    "        # 2 - Link Section with the Document\n",
    "        \"MATCH (d:Document {url_hash: $doc_url_hash_val}) MATCH (s:Section {key: $doc_url_hash_val+'|'+$block_idx_val+'|'+$title_hash_val}) MERGE (d)<-[:HAS_DOCUMENT]-(s);\",\n",
    "        # 3 - Link Section with a parent section\n",
    "        \"MATCH (s1:Section {key: $doc_url_hash_val+'|'+$parent_block_idx_val+'|'+$parent_title_hash_val}) MATCH (s2:Section {key: $doc_url_hash_val+'|'+$block_idx_val+'|'+$title_hash_val}) MERGE (s1)<-[:UNDER_SECTION]-(s2);\",\n",
    "        # 4 - Chunk\n",
    "        \"MERGE (c:Chunk {key: $doc_url_hash_val+'|'+$block_idx_val+'|'+$sentences_hash_val}) ON CREATE SET c.sentences = $sentences_val, c.sentences_hash = $sentences_hash_val, c.block_idx = $block_idx_val, c.page_idx = $page_idx_val, c.tag = $tag_val, c.level = $level_val RETURN c;\",\n",
    "        # 5 - Link Chunk to Section\n",
    "        \"MATCH (c:Chunk {key: $doc_url_hash_val+'|'+$block_idx_val+'|'+$sentences_hash_val}) MATCH (s:Section {key:$doc_url_hash_val+'|'+$parent_block_idx_val+'|'+$parent_hash_val}) MERGE (s)<-[:HAS_PARENT]-(c);\",\n",
    "        # 6 - Table\n",
    "        \"MERGE (t:Table {key: $doc_url_hash_val+'|'+$block_idx_val+'|'+$name_val}) ON CREATE SET t.name = $name_val, t.doc_url_hash = $doc_url_hash_val, t.block_idx = $block_idx_val, t.page_idx = $page_idx_val, t.html = $html_val, t.rows = $rows_val RETURN t;\",\n",
    "        # 7 - Link Table to Section\n",
    "        \"MATCH (t:Table {key: $doc_url_hash_val+'|'+$block_idx_val+'|'+$name_val}) MATCH (s:Section {key: $doc_url_hash_val+'|'+$parent_block_idx_val+'|'+$parent_hash_val}) MERGE (s)<-[:HAS_PARENT]-(t);\",\n",
    "        # 8 - Link Table to Document if no parent section\n",
    "        \"MATCH (t:Table {key: $doc_url_hash_val+'|'+$block_idx_val+'|'+$name_val}) MATCH (s:Document {url_hash: $doc_url_hash_val}) MERGE (s)<-[:HAS_PARENT]-(t);\"\n",
    "    ]\n",
    "\n",
    "    driver = GraphDatabase.driver(NEO4J_URL, database=NEO4J_DATABASE, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "\n",
    "    with driver.session() as session:\n",
    "        cypher = \"\"\n",
    "\n",
    "        # 1 - Create Document node\n",
    "        doc_url_val = doc_location\n",
    "        doc_url_hash_val = hashlib.md5(doc_url_val.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "        cypher = cypher_pool[0]\n",
    "        session.run(cypher, doc_url_hash_val=doc_url_hash_val, doc_url_val=doc_url_val)\n",
    "\n",
    "        # 2 - Create Section nodes\n",
    "        \n",
    "        countSection = 0\n",
    "        for sec in doc.sections():\n",
    "            sec_title_val = sec.title\n",
    "            sec_title_hash_val = hashlib.md5(sec_title_val.encode(\"utf-8\")).hexdigest()\n",
    "            sec_tag_val = sec.tag\n",
    "            sec_level_val = sec.level\n",
    "            sec_page_idx_val = sec.page_idx\n",
    "            sec_block_idx_val = sec.block_idx\n",
    "\n",
    "            # MERGE section node\n",
    "            if not sec_tag_val == 'table':\n",
    "                cypher = cypher_pool[1]\n",
    "                session.run(cypher, page_idx_val=sec_page_idx_val\n",
    "                                , title_hash_val=sec_title_hash_val\n",
    "                                , title_val=sec_title_val\n",
    "                                , tag_val=sec_tag_val\n",
    "                                , level_val=sec_level_val\n",
    "                                , block_idx_val=sec_block_idx_val\n",
    "                                , doc_url_hash_val=doc_url_hash_val\n",
    "                            )\n",
    "\n",
    "                # Link Section with a parent section or Document\n",
    "\n",
    "                sec_parent_val = str(sec.parent.to_text())\n",
    "\n",
    "                if sec_parent_val == \"None\":    # use Document as parent\n",
    "\n",
    "                    cypher = cypher_pool[2]\n",
    "                    session.run(cypher, page_idx_val=sec_page_idx_val\n",
    "                                    , title_hash_val=sec_title_hash_val\n",
    "                                    , doc_url_hash_val=doc_url_hash_val\n",
    "                                    , block_idx_val=sec_block_idx_val\n",
    "                                )\n",
    "\n",
    "                else:   # use parent section\n",
    "                    sec_parent_title_hash_val = hashlib.md5(sec_parent_val.encode(\"utf-8\")).hexdigest()\n",
    "                    sec_parent_page_idx_val = sec.parent.page_idx\n",
    "                    sec_parent_block_idx_val = sec.parent.block_idx\n",
    "\n",
    "                    cypher = cypher_pool[3]\n",
    "                    session.run(cypher, page_idx_val=sec_page_idx_val\n",
    "                                    , title_hash_val=sec_title_hash_val\n",
    "                                    , block_idx_val=sec_block_idx_val\n",
    "                                    , parent_page_idx_val=sec_parent_page_idx_val\n",
    "                                    , parent_title_hash_val=sec_parent_title_hash_val\n",
    "                                    , parent_block_idx_val=sec_parent_block_idx_val\n",
    "                                    , doc_url_hash_val=doc_url_hash_val\n",
    "                                )\n",
    "            # **** if sec_parent_val == \"None\":    \n",
    "\n",
    "            countSection += 1\n",
    "        # **** for sec in doc.sections():\n",
    "\n",
    "        \n",
    "        # ------- Continue within the blocks -------\n",
    "        # 3 - Create Chunk nodes from chunks\n",
    "            \n",
    "        countChunk = 0\n",
    "        for chk in doc.chunks():\n",
    "\n",
    "            chunk_block_idx_val = chk.block_idx\n",
    "            chunk_page_idx_val = chk.page_idx\n",
    "            chunk_tag_val = chk.tag\n",
    "            chunk_level_val = chk.level\n",
    "            chunk_sentences = \"\\n\".join(chk.sentences)\n",
    "\n",
    "            # MERGE Chunk node\n",
    "            if not chunk_tag_val == 'table':\n",
    "                chunk_sentences_hash_val = hashlib.md5(chunk_sentences.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "                # MERGE chunk node\n",
    "                cypher = cypher_pool[4]\n",
    "                session.run(cypher, sentences_hash_val=chunk_sentences_hash_val\n",
    "                                , sentences_val=chunk_sentences\n",
    "                                , block_idx_val=chunk_block_idx_val\n",
    "                                , page_idx_val=chunk_page_idx_val\n",
    "                                , tag_val=chunk_tag_val\n",
    "                                , level_val=chunk_level_val\n",
    "                                , doc_url_hash_val=doc_url_hash_val\n",
    "                            )\n",
    "            \n",
    "                # Link chunk with a section\n",
    "                # Chunk always has a parent section \n",
    "\n",
    "                chk_parent_val = str(chk.parent.to_text())\n",
    "                \n",
    "                if not chk_parent_val == \"None\":\n",
    "                    chk_parent_hash_val = hashlib.md5(chk_parent_val.encode(\"utf-8\")).hexdigest()\n",
    "                    chk_parent_page_idx_val = chk.parent.page_idx\n",
    "                    chk_parent_block_idx_val = chk.parent.block_idx\n",
    "\n",
    "                    cypher = cypher_pool[5]\n",
    "                    session.run(cypher, sentences_hash_val=chunk_sentences_hash_val\n",
    "                                    , block_idx_val=chunk_block_idx_val\n",
    "                                    , parent_hash_val=chk_parent_hash_val\n",
    "                                    , parent_block_idx_val=chk_parent_block_idx_val\n",
    "                                    , doc_url_hash_val=doc_url_hash_val\n",
    "                                )\n",
    "                    \n",
    "                # Link sentence \n",
    "                #   >> TO DO for smaller token length\n",
    "\n",
    "                countChunk += 1\n",
    "        # **** for chk in doc.chunks(): \n",
    "\n",
    "        # 4 - Create Table nodes\n",
    "\n",
    "        countTable = 0\n",
    "        for tb in doc.tables():\n",
    "            page_idx_val = tb.page_idx\n",
    "            block_idx_val = tb.block_idx\n",
    "            name_val = 'block#' + str(block_idx_val) + '_' + tb.name\n",
    "            html_val = tb.to_html()\n",
    "            rows_val = len(tb.rows)\n",
    "\n",
    "            # MERGE table node\n",
    "\n",
    "            cypher = cypher_pool[6]\n",
    "            session.run(cypher, block_idx_val=block_idx_val\n",
    "                            , page_idx_val=page_idx_val\n",
    "                            , name_val=name_val\n",
    "                            , html_val=html_val\n",
    "                            , rows_val=rows_val\n",
    "                            , doc_url_hash_val=doc_url_hash_val\n",
    "                        )\n",
    "            \n",
    "            # Link table with a section\n",
    "            # Table always has a parent section \n",
    "\n",
    "            table_parent_val = str(tb.parent.to_text())\n",
    "            \n",
    "            if not table_parent_val == \"None\":\n",
    "                table_parent_hash_val = hashlib.md5(table_parent_val.encode(\"utf-8\")).hexdigest()\n",
    "                table_parent_page_idx_val = tb.parent.page_idx\n",
    "                table_parent_block_idx_val = tb.parent.block_idx\n",
    "\n",
    "                cypher = cypher_pool[7]\n",
    "                session.run(cypher, name_val=name_val\n",
    "                                , block_idx_val=block_idx_val\n",
    "                                , parent_page_idx_val=table_parent_page_idx_val\n",
    "                                , parent_hash_val=table_parent_hash_val\n",
    "                                , parent_block_idx_val=table_parent_block_idx_val\n",
    "                                , doc_url_hash_val=doc_url_hash_val\n",
    "                            )\n",
    "\n",
    "            else:   # link table to Document\n",
    "                cypher = cypher_pool[8]\n",
    "                session.run(cypher, name_val=name_val\n",
    "                                , block_idx_val=block_idx_val\n",
    "                                , doc_url_hash_val=doc_url_hash_val\n",
    "                            )\n",
    "            countTable += 1\n",
    "\n",
    "        # **** for tb in doc.tables():\n",
    "        \n",
    "        print(f'\\'{doc_url_val}\\' Done! Summary: ')\n",
    "        print('#Sections: ' + str(countSection))\n",
    "        print('#Chunks: ' + str(countChunk))\n",
    "        print('#Tables: ' + str(countTable))\n",
    "\n",
    "    driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "{code: Neo.ClientError.Procedure.ProcedureCallFailed} {message: Failed to invoke procedure `db.index.vector.createNodeIndex`: Caused by: org.neo4j.kernel.api.exceptions.schema.EquivalentSchemaRuleAlreadyExistsException: An equivalent index already exists, 'Index( id=10, name='chunkVectorIndex', type='VECTOR', schema=(:Embedding {value}), indexProvider='vector-2.0' )'.}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGqlError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;31mGqlError\u001b[0m: {gql_status: 22N70} {gql_status_description: error: data exception - equivalent index already exists. An equivalent index already exists: 'chunkVectorIndex'} {message: An equivalent index already exists, 'Index( id=10, name='chunkVectorIndex', type='VECTOR', schema=(:Embedding {value}), indexProvider='vector-2.0' )'.} {diagnostic_record: {'_classification': 'CLIENT_ERROR', 'OPERATION': '', 'OPERATION_CODE': '0', 'CURRENT_SCHEMA': '/'}} {raw_classification: CLIENT_ERROR}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# create constraints and indexes\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m initialiseNeo4j()\n",
      "Cell \u001b[0;32mIn[6], line 25\u001b[0m, in \u001b[0;36minitialiseNeo4j\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m driver\u001b[38;5;241m.\u001b[39msession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cypher \u001b[38;5;129;01min\u001b[39;00m cypher_schema:\n\u001b[0;32m---> 25\u001b[0m         session\u001b[38;5;241m.\u001b[39mrun(cypher)\n\u001b[1;32m     26\u001b[0m driver\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/neo4j/_sync/work/session.py:328\u001b[0m, in \u001b[0;36mSession.run\u001b[0;34m(self, query, parameters, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m bookmarks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_bookmarks()\n\u001b[1;32m    327\u001b[0m parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(parameters \u001b[38;5;129;01mor\u001b[39;00m {}, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auto_result\u001b[38;5;241m.\u001b[39m_run(\n\u001b[1;32m    329\u001b[0m     query,\n\u001b[1;32m    330\u001b[0m     parameters,\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mdatabase,\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mimpersonated_user,\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mdefault_access_mode,\n\u001b[1;32m    334\u001b[0m     bookmarks,\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mnotifications_min_severity,\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mnotifications_disabled_classifications,\n\u001b[1;32m    337\u001b[0m )\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auto_result\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/neo4j/_sync/work/result.py:236\u001b[0m, in \u001b[0;36mResult._run\u001b[0;34m(self, query, parameters, db, imp_user, access_mode, bookmarks, notifications_min_severity, notifications_disabled_classifications)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pull()\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39msend_all()\n\u001b[0;32m--> 236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attach()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/neo4j/_sync/work/result.py:430\u001b[0m, in \u001b[0;36mResult._attach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exhausted \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mfetch_message()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/neo4j/_sync/io/_common.py:184\u001b[0m, in \u001b[0;36mConnectionErrorHandler.__getattr__.<locals>.outer.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 184\u001b[0m         func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (Neo4jError, ServiceUnavailable, SessionExpired) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39miscoroutinefunction(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__on_error)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/neo4j/_sync/io/_bolt.py:864\u001b[0m, in \u001b[0;36mBolt.fetch_message\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;66;03m# Receive exactly one message\u001b[39;00m\n\u001b[1;32m    861\u001b[0m tag, fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minbox\u001b[38;5;241m.\u001b[39mpop(\n\u001b[1;32m    862\u001b[0m     hydration_hooks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponses[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mhydration_hooks\n\u001b[1;32m    863\u001b[0m )\n\u001b[0;32m--> 864\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_message(tag, fields)\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midle_since \u001b[38;5;241m=\u001b[39m monotonic()\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/neo4j/_sync/io/_bolt5.py:1208\u001b[0m, in \u001b[0;36mBolt5x7._process_message\u001b[0;34m(self, tag, fields)\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enrich_error_diagnostic_record(summary_metadata)\n\u001b[1;32m   1207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1208\u001b[0m     response\u001b[38;5;241m.\u001b[39mon_failure(summary_metadata \u001b[38;5;129;01mor\u001b[39;00m {})\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ServiceUnavailable, DatabaseUnavailable):\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/neo4j/_sync/io/_common.py:254\u001b[0m, in \u001b[0;36mResponse.on_failure\u001b[0;34m(self, metadata)\u001b[0m\n\u001b[1;32m    252\u001b[0m handler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandlers\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_summary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    253\u001b[0m Util\u001b[38;5;241m.\u001b[39mcallback(handler)\n\u001b[0;32m--> 254\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hydrate_error(metadata)\n",
      "\u001b[0;31mClientError\u001b[0m: {code: Neo.ClientError.Procedure.ProcedureCallFailed} {message: Failed to invoke procedure `db.index.vector.createNodeIndex`: Caused by: org.neo4j.kernel.api.exceptions.schema.EquivalentSchemaRuleAlreadyExistsException: An equivalent index already exists, 'Index( id=10, name='chunkVectorIndex', type='VECTOR', schema=(:Embedding {value}), indexProvider='vector-2.0' )'.}"
     ]
    }
   ],
   "source": [
    "# create constraints and indexes\n",
    "\n",
    "initialiseNeo4j()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#PDF files found: 1!\n",
      "'/Users/adityaraj/Downloads/PDF/2308.07134v5.pdf' Done! Summary: \n",
      "#Sections: 65\n",
      "#Chunks: 282\n",
      "#Tables: 6\n",
      "Total time: 0:01:24.605289\n"
     ]
    }
   ],
   "source": [
    "# get all documents under the folder\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "pdf_files = glob.glob(file_location + '/*.pdf')\n",
    "\n",
    "print(f'#PDF files found: {len(pdf_files)}!')\n",
    "pdf_reader = LayoutPDFReader(llmsherpa_api_url)\n",
    "\n",
    "# parse documents and create graph\n",
    "startTime = datetime.now()\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    doc = pdf_reader.read_pdf(pdf_file)\n",
    "\n",
    "    # find the first / in pdf_file from right\n",
    "    idx = pdf_file.rfind('/')\n",
    "    pdf_file_name = pdf_file[idx+1:]\n",
    "\n",
    "    # open a local file to write the JSON\n",
    "    with open(pdf_file_name + '.json', 'w') as f:\n",
    "        # convert doc.json from a list to string\n",
    "        f.write(str(doc.json))\n",
    "\n",
    "    ingestDocumentNeo4j(doc, pdf_file)\n",
    "\n",
    "print(f'Total time: {datetime.now() - startTime}')\n",
    "\n",
    "# DONE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
